# 大模型推理系统实验报告

## 算子部分

`swiglu`算子，根据公式直接对Tensor内部每个元素进行处理即可。

`rms_norm`算子，根据提示，只考虑最后一维度的计算，因而不一定需要实现广播，代码中的实现也只针对最后一维度进行计算。

计算方式记录：根据最后一维度，设长度为$len$,最后维度为$n$,则对每个$\frac{len}{n}$，进行公式的操作即可。

对于`矩阵乘`算子，本次实验仅实现了二维矩阵的乘法，在转置部分，为方便编写代码，使用了额外的内存(可优化部分)，进行计算。

`mlp`算子，直接根据计算过程调用相应的算子即可。

**总结**：对于一些维度高Tensor的计算方式理解不够深刻，比如`rms_norm`算子实现过程中，最后一维度的计算让我困惑很久。广播机制的应用背景和实现等等，还需要进一步的学习

## story部分

* 加载模型部分



* 完成`self-attention`部分



* 完成story功能

实现`self-attention`后，只需要再完成`generate`函数即可，

补全上述功能后，需要完成`model.rs`下的`generate`函数即可，经过`forward`函数，每次输出一个`token`，最后将输出的`token`经过解码得到输出的文件即可。

story完成结果如下:

![story](./img/story_result.png)

## chat部分


chat部分结果如下:
![chat](./img/chat_result.png)

## 尝试创新部分

### 多会话管理实现
运行程序后，在当前终端下，能够实现多会话管理，能够同时进行多个聊天，并实现彼此之间的切换。实现逻辑如下：

对于每个对话，需要保存的是`KV`对和已经输入的历史记录,(使用struct进行存储)，最后靠`Hashmap`进行存储即可，当用户输入的时候，根据特殊词进行触发即可(demo中设置为change)，切换后，可以新建或者回到当初的对话。

效果图如下：

![multi_chat](./img/multi_chat.png)



### 实现多核cpu并行计算



### 加入一个简单的小界面
加入一个简陋的界面，没有什么好说的了，采用，加入一些小控件即可

